<p>Now that we understand how to create and configure rules, let's test our meta-rule from the previous stage by creating another useful rule. This time, we'll create a rule that helps us see which rules are being applied during AI interactions.</p>

<h5>Rule Visibility Helper</h5>

<p>One challenge when working with multiple rules is knowing which ones are actually being applied at any given moment. Let's create a rule that will show us a list of all rules being used during each AI action.</p>

<callout type="chat">
Create a new rule file called rule-visibility.mdc in .cursor/rules folder, add the following content:
rule-visibility

1. Display applied rules at AI action 
2. ONLY if action uses rule. Do not display rules unrelated to an action 

# Rule Visibility

This rule ensures transparency by displaying a list of all rules that are currently being applied at every AI action.

## Requirements
- At the beginning of each response, list all rules that are being applied
- Format the list as a bulleted list with rule names and descriptions
- Include this rule in the list
- Apply this rule to all files and all actions



## Application
- Apply this rule for every edit, search, or response
- This rule should always be applied, regardless of context 
</callout>

<p>Set the rule type to “Always”. This visibility rule will act as a diagnostic tool, helping us understand exactly which rules Cursor is applying during each interaction.</p>

<h5>Verifying Our Setup</h5>

<ul interactive>
    <li title="Check rule creation">
        Verify that rule-visibility.mdc was created and the rule type is set to “Always”<br>
    </li>
</ul>

<h5>Testing Rule Application</h5>

<p>Now let's test if our rules are working properly by creating a simple test function:</p>

<callout type="chat">
Create a new file called test_visibility.py with a simple function that prints "Hello there!"
</callout>

<h5>Observing Rule Application</h5>

<p>In the chat response, you should have noticed:</p>

<ul>
<li>A list of rules being applied</li>
<li>Specific mention of the coding-standards rule</li>
<li>Possibly other rules you've created</li>
</ul><br>

<p>This visibility helps us confirm that our rules are working as expected and gives us insight into Cursor's rule application process.</p>

<ul interactive>
    <li title="Observed rule application">
        Confirm that you saw the coding-standards and rule-visibility rules mentioned in the chat response<br>
    </li>
</ul>

<alert>If something isn't working right, you can make a rule to fix it.
    For example, if test_visibility.py goes to the root folder instead of /src, make a rule to put files in src.
    Below is an example how you can ask chat to create rule but try fixing this yourself.
    This shows how rules help you - you can fix problems and make things work better over time.
    Once you fix it with a rule, that problem won't happen again.
<callout type="chat">
    Create a rule to put all python files in src folder.
</callout>
</alert>

<h5>What Have We Learned?</h5>

<p>This visibility rule demonstrates one of the aspects of Cursor's rule system - the ability to create even meta-tools that improve your workflow with AI. By making rule application visible, you can:</p>

<ul>
<li>Debug rule conflicts</li>
<li>Verify that critical rules are being applied</li>
<li>Understand how Cursor prioritizes different rules</li>
<li>Optimize your rule setup for better results</li>
</ul><br>

Next, we'll explore how to use referencing in rules. 
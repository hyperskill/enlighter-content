<p>Now that we understand how to create and configure rules, let's test our meta-rule from the previous stage by creating another useful rule. This time, we'll create a rule that helps us see which rules are being applied during AI interactions.</p>

<strong style="font-size: 15px;">Rule Visibility Helper</strong><br>

<p>One challenge when working with multiple rules is knowing which ones are actually being applied at any given moment. Let's create a rule that will show us a list of all rules being used during each AI action.</p>

<callout type="chat">
Create a new rule file called rule-visibility.mdc in .cursor/rules folder, set the rule type to “always”, add the following content:
rule-visibility

1. Display applied rules at AI action 
2. ONLY if action uses rule. Do not display rules unrelated to an action 

# Rule Visibility

This rule ensures transparency by displaying a list of all rules that are currently being applied at every AI action.

## Requirements
- At the beginning of each response, list all rules that are being applied
- Format the list as a bulleted list with rule names and descriptions
- Include this rule in the list
- Apply this rule to all files and all actions

## Application
- Apply this rule for every edit, search, or response
- This rule should always be applied, regardless of context 
</callout>

<p>This visibility rule will act as a diagnostic tool, helping us understand exactly which rules Cursor is applying during each interaction.</p>

<strong style="font-size: 15px;">Verifying Our Setup</strong><br>

<ul interactive>
    <li title="Check rule creation">
        Verify that rule-visibility.mdc was created with the correct settings (alwaysApply set to true)<br>
    </li>
</ul>

<p>If the rule type is not set to "always", ask chat to modify the rule to have these settings:</p>

<callout type="chat">
    Set the rule type to rule-visibility rule (rule-visibility.mdc) to “always”.
</callout>
<br>

<strong style="font-size: 15px;">Testing Rule Application</strong><br>

<p>Now let's test if our rules are working properly by creating a simple test function:</p>

<callout type="chat">
Create a new file called test_visibility.py with a simple function that prints "Hello there!"
</callout>

<strong style="font-size: 15px;">Observing Rule Application</strong><br>

<p>In the chat response, you should have noticed:</p>

- A list of rules being applied<br>
- Specific mention of the coding-standards rule<br>
- Possibly other rules you've created<br><br>

<p>This visibility helps us confirm that our rules are working as expected and gives us insight into Cursor's rule application process.</p>

<ul interactive>
    <li title="Observed rule application">
        Confirm that you saw the coding-standards and rule-visibility rules mentioned in the chat response<br>
    </li>
</ul>

<alert>If something isn't working right, you can make a rule to fix it.
    For example, if test_visibility.py goes to the root folder instead of /src, make a rule to put files in src.
    Below is an example how you can ask chat to create rule but try fixing this yourself.
    This shows how rules help you - you can fix problems and make things work better over time.
    Once you fix it with a rule, that problem won't happen again.
<callout type="chat">
    Create a rule to put all python files in src folder.
</callout>
</alert>

<strong style="font-size: 15px;">What Have We Learned?</strong><br>

<p>This visibility rule demonstrates one of the aspects of Cursor's rule system - the ability to create even meta-tools that improve your workflow with AI. By making rule application visible, you can:</p>

- Debug rule conflicts<br>
- Verify that critical rules are being applied<br>
- Understand how Cursor prioritizes different rules<br>
- Optimize your rule setup for better results<br><br>

Next, we'll explore how to use referencing in rules. 